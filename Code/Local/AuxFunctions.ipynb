{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate datasets with data from database (True) or from local files (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectFromDatabase(db):\n",
    "    \n",
    "    if db == True:\n",
    "        \n",
    "        # Ler base de dados EDP e Atualizar a base de dados local\n",
    "        this_session = Session()\n",
    "        df_consumption_ = this_session.query(consumption).all()\n",
    "        df_pv_ = this_session.query(PV).all()\n",
    "        this_session.close()\n",
    "        df_consumption_ = pd.DataFrame(df_consumption_)\n",
    "        df_pv_ = pd.DataFrame(df_pv_)\n",
    "        df_consumption_.to_csv(\"consumption.csv\")\n",
    "        df_pv_.to_csv(\"PV.csv\")\n",
    "        \n",
    "    elif db == False:\n",
    "        \n",
    "        # Ler base de dados local\n",
    "        df_consumption_ = pd.read_csv(\"consumption.csv\")\n",
    "        df_pv_ = pd.read_csv(\"PV.csv\")\n",
    "        df_consumption_ = df_consumption_.drop(columns=['Unnamed: 0'])\n",
    "        df_pv_ = df_pv_.drop(columns=['Unnamed: 0'])\n",
    "        df_consumption_.Timestamp =  pd.to_datetime(df_consumption_.Timestamp)\n",
    "        df_pv_.Timestamp =  pd.to_datetime(df_pv_.Timestamp)\n",
    "        \n",
    "    return df_pv_, df_consumption_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset already built (True) or build new dataset (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(local):\n",
    "    \n",
    "    if local == True:\n",
    "    \n",
    "        data = pd.read_csv(\"dfinal.csv\")\n",
    "        data = data.set_index('Timestamp')\n",
    "        data = data.astype('float64')\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        dataset1 = np.genfromtxt('dados__Rad.dat', delimiter=',', skip_header=3, missing_values='Missing',names=True,dtype=None)\n",
    "        dataset2 = np.genfromtxt('dados__Met.dat', delimiter=',', skip_header=3, missing_values='Missing',names=True,dtype=None)\n",
    "\n",
    "        df1 = pd.DataFrame(data=dataset1)\n",
    "        df2 = pd.DataFrame(data=dataset2)\n",
    "\n",
    "        df1.columns = [\"Timestamp\",\"RECORD\",\"Avg_GHI\",\"Avg_DHI\",\"Avg_POA\",\"Avg_DNI\",\"Avg_cosDNI\",\"Avg_closGHI\",\"Std_GHI\",\"Std_DHI\",\"Std_POA\",\"Std_DNI\",\"Std_cosDNI\",\"Std_closGHI\",\"Min_GHI\",\"Min_DHI\",\"Min_POA\",\"Min_DNI\",\"Min_cosDNI\",\"Min_closGHI\",\"Max_GHI\",\"Max_DHI\",\"Max_POA\",\"Max_DNI\",\"Max_cosDNI\",\"Max_closGHI\",\"phi\",\"theta\",\"SensorT\"]\n",
    "        df2.columns = [\"Timestamp\",\"RECORD\",\"T_amb_min\",\"T_amb_max\",\"T_amb_avg\",\"T_dp_avg\",\"RH_min\",\"RH_max\",\"RH_avg\",\"AH_min\",\"AH_max\",\"AH_avg\",\"p_amb_min\",\"p_amb_max\",\"p_amb_avg\",\"rho_act\",\"v_min\",\"v_max\",\"v_avg\",\"v_vectavg\",\"v_dir_min\",\"v_dir_max\",\"v_dir_vectavg\"]\n",
    "\n",
    "        df1['Timestamp'] = pd.to_datetime(df1['Timestamp'].str.decode(\"utf-8\"), format='\"%Y-%m-%d %H:%M:%S\"')\n",
    "        df2['Timestamp'] = pd.to_datetime(df2['Timestamp'].str.decode(\"utf-8\"), format='\"%Y-%m-%d %H:%M:%S\"')\n",
    "        df3 = pd.merge(df1,df2, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "        PV = df_pv.copy()\n",
    "        consumption = df_consumption.copy()\n",
    "\n",
    "        consumption = consumption.set_index('Timestamp')\n",
    "        df3.rename(columns={\"Timestamp_x\": \"Timestamp\", \"RECORD_x\": \"Record\"}, inplace=True)\n",
    "\n",
    "        PV['Timestamp'] = PV['Timestamp'].dt.round('min')\n",
    "        PV = PV.groupby('Timestamp').mean().reset_index()\n",
    "        PV = PV.set_index('Timestamp')\n",
    "\n",
    "        idx = pd.period_range(PV.index[0], PV.index[-1], freq='min')\n",
    "        idy = pd.period_range(consumption.index[0], consumption.index[-1], freq='min')\n",
    "\n",
    "        PV = PV.reset_index()\n",
    "        PV = PV.set_index('Timestamp').resample(\"min\").first().reset_index().reindex(columns=PV.columns)\n",
    "        cols = PV.columns.difference(['I1', 'I2', 'I3', 'V1', 'V2', 'V3', 'ActPwr'])\n",
    "        PV[cols] = PV[cols].ffill()\n",
    "        PV['ActPwr'] = PV['ActPwr']*1000\n",
    "\n",
    "        consumption = consumption.reset_index()\n",
    "        consumption = consumption.set_index('Timestamp').resample(\"min\").first().reset_index().reindex(columns=consumption.columns)\n",
    "        cols = consumption.columns.difference(['Ir','Is','It','Vrs','Vst','Vtr','P','S'])\n",
    "        consumption[cols] = consumption[cols].ffill()\n",
    "\n",
    "        consumption = consumption.set_index('Timestamp')\n",
    "        df3 = df3.set_index('Timestamp')\n",
    "\n",
    "        PV_original = PV.copy()\n",
    "        PV = PV_original[['Timestamp', 'ActPwr']].copy()\n",
    "\n",
    "        consumption_original = consumption.copy()\n",
    "        consumption = consumption_original[['P']]\n",
    "\n",
    "        # Sun Irradiation Theoretical Calculation\n",
    "\n",
    "        panel = solar_panel(500, 0.15, id_name='EDP')  # surface, efficiency and name\n",
    "        panel.set_orientation(array([0, 0, -1]))  # upwards\n",
    "        panel.set_position(38.707089, -9.148882, 0)  # LISBON latitude, longitude, altitude\n",
    "\n",
    "        PV = PV.reset_index()\n",
    "        PV['Theoretical Value'] = PV['Timestamp'].apply(lambda x: fnc(x.year, x.month, x.day, x.hour, x.minute))# year, month, day, hour, minute\n",
    "        PV = PV.set_index('Timestamp')\n",
    "\n",
    "        PV['Theoretical Value'] = PV['Theoretical Value'].shift(60, axis = 0) #passar tudo para UTC\n",
    "        PV = PV.replace(np.nan, '-1')\n",
    "\n",
    "        PREV = df4 = pd.merge(df3, PV, left_index=True, right_index=True)\n",
    "\n",
    "        PREV = PREV.drop(columns=['Timestamp_y', 'RECORD_y'])\n",
    "\n",
    "        PREV = PREV[['Avg_DHI', 'Avg_GHI', 'Avg_DNI', 'Avg_POA', \\\n",
    "                     'T_amb_avg','RH_avg', 'AH_avg', 'p_amb_avg', 'rho_act', 'v_avg', 'v_dir_vectavg',    \\\n",
    "                     'Theoretical Value', 'ActPwr']].copy()\n",
    "\n",
    "        PREV = PREV.replace('-1', np.nan)\n",
    "\n",
    "        NOITE = PREV.copy()\n",
    "        NOITE['ActPwr_noite'] = NOITE.apply(f, axis=1)\n",
    "\n",
    "        dataaux=NOITE.copy()\n",
    "\n",
    "        INT = NOITE.copy()\n",
    "        INT['Interpolation'] = INT['ActPwr_noite'].interpolate(method='polynomial', limit=30, order=2)\n",
    "\n",
    "        dataaux['Interpolation'] = INT['Interpolation'].copy()\n",
    "\n",
    "        INT['Interpolation'] = INT['Interpolation'].replace(np.nan, '-1000')\n",
    "        INT['Interpolation_Final'] = INT.apply(s, axis=1)\n",
    "        INT['Interpolation'] = INT['Interpolation'].replace('-1000',np.nan)\n",
    "\n",
    "        INT = INT.drop(['ActPwr', 'ActPwr_noite', 'Interpolation'], axis=1)\n",
    "        INT = INT.rename(columns={\"Interpolation_Final\": \"ActPwr\"})\n",
    "\n",
    "        consumption = consumption.interpolate(method='polynomial', limit=30, order=2)\n",
    "\n",
    "        dfinal = pd.concat([INT, consumption], axis=1, sort = False, join = 'inner')\n",
    "        dfinal = dfinal.rename(columns={\"Interpolation_Final\": \"ActPwr\"})\n",
    "        dfinal = dfinal.reset_index()\n",
    "        dfinal = dfinal.set_index('Timestamp')\n",
    "\n",
    "        dfinal['hour'] = dfinal.index.hour\n",
    "        dfinal['day_of_month'] = dfinal.index.day\n",
    "        dfinal['day_of_week'] = dfinal.index.dayofweek\n",
    "        dfinal['month'] = dfinal.index.month\n",
    "        dfinal['holiday'] = dfinal.apply(holiday, axis=1)\n",
    "        dfinal['AvailablePower'] = 1200000 - dfinal['P'] + dfinal['ActPwr']\n",
    "\n",
    "        dfinal = dfinal.astype('float64')\n",
    "\n",
    "        dfinal.to_csv(\"dfinal.csv\")\n",
    "        \n",
    "        data = dfinal.copy()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predicted):\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    \"\"\" Mean Squared Error \"\"\"\n",
    "    return np.mean(np.square(_error(actual, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    \"\"\" Root Mean Squared Error \"\"\"\n",
    "    return np.sqrt(mse(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(actual, predicted):\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    \"\"\" Mean Absolute Error \"\"\"\n",
    "    return np.mean(np.abs(_error(actual, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the solar power output based on datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnc(year, month, day, hour, minute):\n",
    "    panel.set_datetime(datetime(year, month, day, hour, minute))\n",
    "    return panel.power()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary function to interpolate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s(row):\n",
    "    if row['Interpolation'] == '-1000':\n",
    "        return row['Theoretical Value']  \n",
    "    else:\n",
    "        return row['Interpolation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that identifies national holidays and outputs '1' if specific day is holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holiday(row):\n",
    "    if row['day_of_month'] == 1 and row['month'] == 1:\n",
    "        return 1  \n",
    "    if row['day_of_month'] == 25 and row['month'] == 2:\n",
    "        return 1\n",
    "    if row['day_of_month'] == 10 and row['month'] == 4:\n",
    "        return 1\n",
    "    if row['day_of_month'] == 12 and row['month'] == 4:\n",
    "        return 1  \n",
    "    if row['day_of_month'] == 25 and row['month'] == 4:\n",
    "        return 1\n",
    "    if row['day_of_month'] == 1 and row['month'] == 5:\n",
    "        return 1  \n",
    "    if row['day_of_month'] == 10 and row['month'] == 6:\n",
    "        return 1  \n",
    "    if row['day_of_month'] == 11 and row['month'] == 6:\n",
    "        return 1\n",
    "    if row['day_of_month'] == 15 and row['month'] == 8:\n",
    "        return 1\n",
    "    if row['day_of_month'] == 5 and row['month'] == 10:\n",
    "        return 1  \n",
    "    if row['day_of_month'] == 1 and row['month'] == 11:\n",
    "        return 1\n",
    "    if row['day_of_month'] == 1 and row['month'] == 12:\n",
    "        return 1\n",
    "    if row['day_of_month'] == 8 and row['month'] == 12:\n",
    "        return 1  \n",
    "    if row['day_of_month'] == 25 and row['month'] == 12:        \n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"7pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that neutralizes 'Avg_GHI' if it is lower than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row['Avg_GHI'] <= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return row['ActPwr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that extracts prediction vectors with desired shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPredictionVectors(real, predicted):\n",
    "    \n",
    "    rows_real = len(real)\n",
    "    rows_predicted = len(predicted)\n",
    "\n",
    "\n",
    "    real_AvailablePower_5 = []\n",
    "    predicted_AvailablePower_5= []\n",
    "    real_AvailablePower_10 = []\n",
    "    predicted_AvailablePower_10 = []\n",
    "    real_AvailablePower_15 = []\n",
    "    predicted_AvailablePower_15 = []\n",
    "\n",
    "\n",
    "    for i in range(rows_real):\n",
    "        real_AvailablePower_5.append(real[i][0])\n",
    "        real_AvailablePower_10.append(real[i][1])\n",
    "        real_AvailablePower_15.append(real[i][2])\n",
    "\n",
    "\n",
    "    for i in range(rows_predicted):    \n",
    "        predicted_AvailablePower_5.append(predicted[i][0])\n",
    "        predicted_AvailablePower_10.append(predicted[i][1])\n",
    "        predicted_AvailablePower_15.append(predicted[i][2])\n",
    "        \n",
    "    return real_AvailablePower_5, real_AvailablePower_10, real_AvailablePower_15, predicted_AvailablePower_5, predicted_AvailablePower_10, predicted_AvailablePower_15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that commputes and prints training errors (RMSE, MSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTrainErrors(real, predicted):\n",
    "\n",
    "    real_AvailablePower_5, real_AvailablePower_10, real_AvailablePower_15,\\\n",
    "    predicted_AvailablePower_5, predicted_AvailablePower_10, predicted_AvailablePower_15 \\\n",
    "     = extractPredictionVectors(real, predicted)\n",
    "\n",
    "    train_rmse_5 = rmse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Train Available Power RMSE for 5 minutes prediction: %.2f' % train_rmse_5)\n",
    "\n",
    "    train_rmse_10 = rmse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Train Available Power RMSE for 10 minutes prediction: %.2f' % train_rmse_10)\n",
    "\n",
    "    train_rmse_15 = rmse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Train Available Power RMSE for 15 minutes prediction: %.2f' % train_rmse_15)\n",
    "\n",
    "    train_mse_5 = mse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Train Available Power MSE for 5 minutes prediction: %.2f' % train_mse_5)\n",
    "\n",
    "    train_mse_10 = mse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Train Available Power MSE for 10 minutes prediction: %.2f' % train_mse_10)\n",
    "\n",
    "    train_mse_15 = mse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Train Available Power MSE for 15 minutes prediction: %.2f' % train_mse_15)\n",
    "\n",
    "    train_mae_5 = mae(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Train Available Power MAE in 5 minutes: %.2f' % train_mae_5)\n",
    "\n",
    "    train_mae_10 = mae(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Train Available Power MAE in 10 minutes: %.2f' % train_mae_10)\n",
    "\n",
    "    train_mae_15 = mae(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Train Available Power MAE in 15 minutes: %.2f' % train_mae_15)\n",
    "    \n",
    "    return train_rmse_5, train_rmse_10, train_rmse_15, \\\n",
    "           train_mse_5, train_mse_10, train_mse_15, \\\n",
    "           train_mae_5, train_mae_10, train_mae_15\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that commputes and prints training errors normalized (RMSE, MSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTrainErrorsNormalized(real, predicted):\n",
    "\n",
    "    real_AvailablePower_5, real_AvailablePower_10, real_AvailablePower_15,\\\n",
    "    predicted_AvailablePower_5, predicted_AvailablePower_10, predicted_AvailablePower_15 \\\n",
    "     = extractPredictionVectors(real, predicted)\n",
    "\n",
    "    train_rmse_5 = rmse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Train Available Power RMSE for 5 minutes prediction: %.6f' % train_rmse_5)\n",
    "\n",
    "    train_rmse_10 = rmse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Train Available Power RMSE for 10 minutes prediction: %.6f' % train_rmse_10)\n",
    "\n",
    "    train_rmse_15 = rmse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Train Available Power RMSE for 15 minutes prediction: %.6f' % train_rmse_15)\n",
    "\n",
    "    train_mse_5 = mse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Train Available Power MSE for 5 minutes prediction: %.6f' % train_mse_5)\n",
    "\n",
    "    train_mse_10 = mse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Train Available Power MSE for 10 minutes prediction: %.6f' % train_mse_10)\n",
    "\n",
    "    train_mse_15 = mse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Train Available Power MSE for 15 minutes prediction: %.6f' % train_mse_15)\n",
    "\n",
    "    train_mae_5 = mae(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Train Available Power MAE in 5 minutes: %.6f' % train_mae_5)\n",
    "\n",
    "    train_mae_10 = mae(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Train Available Power MAE in 10 minutes: %.6f' % train_mae_10)\n",
    "\n",
    "    train_mae_15 = mae(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Train Available Power MAE in 15 minutes: %.6f' % train_mae_15)\n",
    "    \n",
    "    return train_rmse_5, train_rmse_10, train_rmse_15, \\\n",
    "           train_mse_5, train_mse_10, train_mse_15, \\\n",
    "           train_mae_5, train_mae_10, train_mae_15\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that commputes and prints validation errors (RMSE, MSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printValidationErrors(real, predicted):\n",
    "\n",
    "    real_AvailablePower_5, real_AvailablePower_10, real_AvailablePower_15,\\\n",
    "    predicted_AvailablePower_5, predicted_AvailablePower_10, predicted_AvailablePower_15 \\\n",
    "     = extractPredictionVectors(real, predicted)\n",
    "\n",
    "    validation_rmse_5 = rmse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Validation Available Power RMSE for 5 minutes prediction: %.2f' % validation_rmse_5)\n",
    "\n",
    "    validation_rmse_10 = rmse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Validation Available Power RMSE for 10 minutes prediction: %.2f' % validation_rmse_10)\n",
    "\n",
    "    validation_rmse_15 = rmse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Validation Available Power RMSE for 15 minutes prediction: %.2f' % validation_rmse_15)\n",
    "\n",
    "\n",
    "    validation_mse_5 = mse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Validation Available Power MSE for 5 minutes prediction: %.2f' % validation_mse_5)\n",
    "\n",
    "    validation_mse_10 = mse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Validation Available Power MSE for 10 minutes prediction: %.2f' % validation_mse_10)\n",
    "\n",
    "    validation_mse_15 = mse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Validation Available Power MSE for 15 minutes prediction: %.2f' % validation_mse_15)\n",
    "\n",
    "\n",
    "    validation_mae_5 = mae(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Validation Available Power MAE in 5 minutes: %.2f' % validation_mae_5)\n",
    "\n",
    "    validation_mae_10 = mae(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Validation Available Power MAE in 10 minutes: %.2f' % validation_mae_10)\n",
    "\n",
    "    validation_mae_15 = mae(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Validation Available Power MAE in 15 minutes: %.2f' % validation_mae_15)\n",
    "    \n",
    "    return validation_rmse_5, validation_rmse_10, validation_rmse_15, \\\n",
    "           validation_mse_5, validation_mse_10, validation_mse_15, \\\n",
    "           validation_mae_5, validation_mae_10, validation_mae_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that commputes and prints validation errors normalized (RMSE, MSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printValidationErrorsNormalized(real, predicted):\n",
    "\n",
    "    real_AvailablePower_5, real_AvailablePower_10, real_AvailablePower_15,\\\n",
    "    predicted_AvailablePower_5, predicted_AvailablePower_10, predicted_AvailablePower_15 \\\n",
    "     = extractPredictionVectors(real, predicted)\n",
    "\n",
    "    validation_rmse_5 = rmse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Validation Available Power RMSE for 5 minutes prediction: %.6f' % validation_rmse_5)\n",
    "\n",
    "    validation_rmse_10 = rmse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Validation Available Power RMSE for 10 minutes prediction: %.6f' % validation_rmse_10)\n",
    "\n",
    "    validation_rmse_15 = rmse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Validation Available Power RMSE for 15 minutes prediction: %.6f' % validation_rmse_15)\n",
    "\n",
    "    validation_mse_5 = mse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Validation Available Power MSE for 5 minutes prediction: %.6f' % validation_mse_5)\n",
    "\n",
    "    validation_mse_10 = mse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Validation Available Power MSE for 10 minutes prediction: %.6f' % validation_mse_10)\n",
    "\n",
    "    validation_mse_15 = mse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Validation Available Power MSE for 15 minutes prediction: %.6f' % validation_mse_15)\n",
    "\n",
    "    validation_mae_5 = mae(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Validation Available Power MAE in 5 minutes: %.6f' % validation_mae_5)\n",
    "\n",
    "    validation_mae_10 = mae(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Validation Available Power MAE in 10 minutes: %.6f' % validation_mae_10)\n",
    "\n",
    "    validation_mae_15 = mae(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Validation Available Power MAE in 15 minutes: %.6f' % validation_mae_15)\n",
    "    \n",
    "    return validation_rmse_5, validation_rmse_10, validation_rmse_15, \\\n",
    "           validation_mse_5, validation_mse_10, validation_mse_15, \\\n",
    "           validation_mae_5, validation_mae_10, validation_mae_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that commputes and prints test errors (RMSE, MSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTestErrors(real, predicted):\n",
    "\n",
    "    real_AvailablePower_5, real_AvailablePower_10, real_AvailablePower_15,\\\n",
    "    predicted_AvailablePower_5, predicted_AvailablePower_10, predicted_AvailablePower_15 \\\n",
    "     = extractPredictionVectors(real, predicted)\n",
    "\n",
    "    test_rmse_5 = rmse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Test Available Power RMSE for 5 minutes prediction: %.2f' % test_rmse_5)\n",
    "\n",
    "    test_rmse_10 = rmse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Test Available Power RMSE for 10 minutes prediction: %.2f' % test_rmse_10)\n",
    "\n",
    "    test_rmse_15 = rmse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Test Available Power RMSE for 15 minutes prediction: %.2f' % test_rmse_15)\n",
    "\n",
    "    test_mse_5 = mse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Test Available Power MSE for 5 minutes prediction: %.2f' % test_mse_5)\n",
    "\n",
    "    test_mse_10 = mse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Test Available Power MSE for 10 minutes prediction: %.2f' % test_mse_10)\n",
    "\n",
    "    test_mse_15 = mse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Test Available Power MSE for 15 minutes prediction: %.2f' % test_mse_15)\n",
    "\n",
    "    test_mae_5 = mae(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Test Available Power MAE in 5 minutes: %.2f' % test_mae_5)\n",
    "\n",
    "    test_mae_10 = mae(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Test Available Power MAE in 10 minutes: %.2f' % test_mae_10)\n",
    "\n",
    "    test_mae_15 = mae(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Test Available Power MAE in 15 minutes: %.2f' % test_mae_15)\n",
    "    \n",
    "    \n",
    "    return test_rmse_5, test_rmse_10, test_rmse_15, test_mse_5, test_mse_10, test_mse_15, test_mae_5, test_mae_10, test_mae_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that commputes and prints test errors normalized (RMSE, MSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTestErrorsNormalized(real, predicted):\n",
    "\n",
    "    real_AvailablePower_5, real_AvailablePower_10, real_AvailablePower_15,\\\n",
    "    predicted_AvailablePower_5, predicted_AvailablePower_10, predicted_AvailablePower_15 \\\n",
    "     = extractPredictionVectors(real, predicted)\n",
    "\n",
    "    test_rmse_5 = rmse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Test Available Power RMSE for 5 minutes prediction: %.6f' % test_rmse_5)\n",
    "\n",
    "    test_rmse_10 = rmse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Test Available Power RMSE for 10 minutes prediction: %.6f' % test_rmse_10)\n",
    "\n",
    "    test_rmse_15 = rmse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Test Available Power RMSE for 15 minutes prediction: %.6f' % test_rmse_15)\n",
    "\n",
    "    test_mse_5 = mse(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Test Available Power MSE for 5 minutes prediction: %.6f' % test_mse_5)\n",
    "\n",
    "    test_mse_10 = mse(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Test Available Power MSE for 10 minutes prediction: %.6f' % test_mse_10)\n",
    "\n",
    "    test_mse_15 = mse(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Test Available Power MSE for 15 minutes prediction: %.6f' % test_mse_15)\n",
    "\n",
    "    test_mae_5 = mae(real_AvailablePower_5, predicted_AvailablePower_5)\n",
    "    print('Test Available Power MAE in 5 minutes: %.6f' % test_mae_5)\n",
    "\n",
    "    test_mae_10 = mae(real_AvailablePower_10, predicted_AvailablePower_10)\n",
    "    print('Test Available Power MAE in 10 minutes: %.6f' % test_mae_10)\n",
    "\n",
    "    test_mae_15 = mae(real_AvailablePower_15, predicted_AvailablePower_15)\n",
    "    print('Test Available Power MAE in 15 minutes: %.6f' % test_mae_15)\n",
    "    \n",
    "    \n",
    "    return test_rmse_5, test_rmse_10, test_rmse_15, test_mse_5, test_mse_10, test_mse_15, test_mae_5, test_mae_10, test_mae_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that prints graph with loss error evolution over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(history, model, dataset):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(history.history['loss'],label='Train MSE')\n",
    "    plt.plot(history.history['val_loss'],label='Validation MSE')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('mse')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig('Images/' + model + '_Loss_' + dataset)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for training model, with or without validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainX, trainY, valX, valY, batch, epoch_count, cb, val):\n",
    "    \n",
    "    if val == True:    \n",
    "        history = model.fit(trainX, trainY, batch_size=batch, epochs=epoch_count, \\\n",
    "                        callbacks=cb, validation_data = (valX, valY))\n",
    "    else:    \n",
    "        history = model.fit(trainX, trainY, batch_size=batch, epochs=epoch_count)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for forcing dropout while testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermanentDropout(Dropout):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(PermanentDropout, self).__init__(rate, **kwargs)\n",
    "        self.uses_learning_phase = False\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(x)\n",
    "            x = K.dropout(x, self.rate, noise_shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for creating Encoder-Decoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(steps_before, steps_after, cnn, feature_count, units, layer, ft, intervals):\n",
    "    \"\"\" \n",
    "        creates, compiles and returns a RNN model \n",
    "        @param steps_before: the number of previous time steps (input)\n",
    "        @param steps_after: the number of posterior time steps (output or predictions)\n",
    "        @param feature_count: the number of features in the model\n",
    "        @param hidden_neurons: the number of hidden neurons per LSTM layer\n",
    "    \"\"\"       \n",
    "    from tensorflow.keras.layers import Lambda\n",
    "    from tensorflow.keras import backend as K\n",
    "\n",
    "    \n",
    "    \n",
    "    if intervals == True:\n",
    "    \n",
    "        if layer == 'GRU':\n",
    "\n",
    "            if cnn == True:\n",
    "                model = Sequential()\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu', input_shape=(steps_before, feature_count),padding = 'causal'))\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(GRU(units, activation='relu', return_sequences=True))\n",
    "                model.add(Lambda(lambda x: K.dropout(x, level=0.2)))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "            else:\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(GRU(ft, activation='relu', input_shape=(steps_before, feature_count)))\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(GRU(units, activation='relu', return_sequences=True))\n",
    "                model.add(Lambda(lambda x: K.dropout(x, level=0.2)))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "                \n",
    "\n",
    "\n",
    "        elif layer == 'LSTM':\n",
    "\n",
    "            if cnn == True:\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu', input_shape=(steps_before, feature_count),padding = 'causal'))\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(LSTM(units, activation='relu', return_sequences=True))\n",
    "                model.add(Lambda(lambda x: K.dropout(x, level=0.2)))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "            else:\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(ft, activation='relu', input_shape=(steps_before, feature_count)))\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(LSTM(units, activation='relu', return_sequences=True))\n",
    "                model.add(Lambda(lambda x: K.dropout(x, level=0.2)))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "        else:\n",
    "            print('Error: Type of layer not defined')\n",
    "       \n",
    "    else:\n",
    "    \n",
    "        if layer == 'GRU':\n",
    "\n",
    "            if cnn == True:\n",
    "                model = Sequential()\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu', input_shape=(steps_before, feature_count),padding = 'causal'))\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(GRU(units, activation='relu', return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "            else:\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(GRU(ft, activation='relu', input_shape=(steps_before, feature_count)))\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(GRU(units, activation='relu', return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "        elif layer == 'LSTM':\n",
    "\n",
    "            if cnn == True:\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu', input_shape=(steps_before, feature_count),padding = 'causal'))\n",
    "                model.add(Conv1D(filters=ft, kernel_size=2, activation='relu'))\n",
    "                model.add(MaxPooling1D(pool_size=2))\n",
    "                model.add(Flatten())\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(LSTM(units, activation='relu', return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "            else:\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(ft, activation='relu', input_shape=(steps_before, feature_count)))\n",
    "                model.add(RepeatVector(steps_after))\n",
    "                model.add(LSTM(units, activation='relu', return_sequences=True))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(TimeDistributed(Dense(1)))\n",
    "        else:\n",
    "            print('Error: Type of layer not defined')        \n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics = ['mae', 'mse', tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for creating the vanilla models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_vanilla(steps_before, feature_count, units, layer, intervals):\n",
    "    \"\"\" \n",
    "        creates, compiles and returns a RNN model \n",
    "        @param steps_before: the number of previous time steps (input)\n",
    "        @param steps_after: the number of posterior time steps (output or predictions)\n",
    "        @param feature_count: the number of features in the model\n",
    "        @param hidden_neurons: the number of hidden neurons per LSTM layer\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    from tensorflow.keras.layers import Lambda\n",
    "    from tensorflow.keras import backend as K\n",
    "\n",
    "    \n",
    "    if intervals == False:\n",
    "    \n",
    "        if layer == 'GRU':\n",
    "\n",
    "            model = keras.Sequential()\n",
    "            model.add(GRU(units=units, input_shape=(steps_before, feature_count)))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(3))\n",
    "\n",
    "        if layer == 'LSTM':\n",
    "\n",
    "            model = keras.Sequential()\n",
    "            model.add(LSTM(units=units, input_shape=(steps_before, feature_count)))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(3))\n",
    "\n",
    "    if intervals == True: \n",
    "        \n",
    "        if layer == 'GRU':\n",
    "\n",
    "            model = keras.Sequential()\n",
    "            model.add(GRU(units=units, input_shape=(steps_before, feature_count)))\n",
    "            model.add(Lambda(lambda x: K.dropout(x, level=0.2)))\n",
    "            model.add(Dense(3))\n",
    "\n",
    "        if layer == 'LSTM':\n",
    "\n",
    "            model = keras.Sequential()\n",
    "            model.add(LSTM(units=units, input_shape=(steps_before, feature_count)))\n",
    "            model.add(Lambda(lambda x: K.dropout(x, level=0.2)))\n",
    "            model.add(Dense(3))\n",
    "\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics = ['mae', 'mse', tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for defining callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacksFunction(model_name, dataset):\n",
    "    \n",
    "    path_checkpoint = './checkpoints/checkpoint_' + model_name + '_' + dataset + '.keras'\n",
    "    \n",
    "    callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                          monitor='val_loss',\n",
    "                                          verbose=1,\n",
    "                                          save_weights_only=True,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "    callback_early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "    callback_tensorboard = TensorBoard(log_dir='./logs/',\n",
    "                                       histogram_freq=0,\n",
    "                                       write_graph=False, profile_batch = 100000000)\n",
    "\n",
    "    callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                           factor=0.1,\n",
    "                                           min_lr=1e-4,\n",
    "                                           patience=1,\n",
    "                                           verbose=1)\n",
    "\n",
    "    class TimeHistory(keras.callbacks.Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.times = []\n",
    "\n",
    "        def on_epoch_begin(self, batch, logs={}):\n",
    "            self.epoch_time_start = time.time()\n",
    "\n",
    "        def on_epoch_end(self, batch, logs={}):\n",
    "            self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    csv_logger = CSVLogger('./training/training_' + model_name + '_' + dataset + '.log', separator=',', append=False)\n",
    "\n",
    "    callbacks = [callback_early_stopping,\n",
    "                 callback_checkpoint,\n",
    "                 callback_tensorboard,\n",
    "                 callback_reduce_lr,\n",
    "                 time_callback,\n",
    "                 csv_logger]\n",
    "    \n",
    "    return callbacks, path_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for creating random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "def data_gen():\n",
    "    while True:\n",
    "        x = np.random.rand(512, 15, 12)  # batch x time x features\n",
    "        yield x, x[:, :, 0] * x[:, :, 1] < 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fucntion responsible for computing feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def var_importance(model):\n",
    "    g = data_gen()\n",
    "    x = np.concatenate([next(g)[0] for _ in range(50)]) # Get a sample of data\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(12):  # iterate over the three features\n",
    "        new_x = x.copy()\n",
    "        perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5\n",
    "        print(f'Variable {i+1}, perturbation effect: {effect:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions responsible for defining variable sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features():\n",
    "    features = ['Avg_DNI',\n",
    "                'Avg_DHI',\n",
    "                'Avg_GHI',\n",
    "                'Avg_POA',\n",
    "                'RH_avg',\n",
    "                'v_dir_vectavg',\n",
    "                'v_avg',\n",
    "                'hour', \n",
    "                'month', \n",
    "                'holiday',\n",
    "                'day_of_week',\n",
    "                'p_amb_avg',\n",
    "                'AvailablePower']\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features2():\n",
    "    features = ['Avg_GHI',\n",
    "                'RH_avg',\n",
    "                'p_amb_avg',\n",
    "                'hour', \n",
    "                'month', \n",
    "                'holiday',\n",
    "                'day_of_week',\n",
    "                'AvailablePower']\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for outputing reconstructed solar production signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReconstruction(dt):\n",
    "\n",
    "    plt.rcParams.update({'figure.figsize':(20,10), 'figure.dpi':300})\n",
    "    font = {'weight' : 'normal','size'   : 28}\n",
    "    plt.rc('font', **font)\n",
    "    pyplot.figure()\n",
    "\n",
    "    dt['ActPwr_final'].plot(label='End of Phase 5', linewidth=4, color='green')\n",
    "    dt['Interpolation'].plot(label='End of Phase 4', color='blue', linewidth=4)\n",
    "    dt['ActPwr_noite'].plot(label='End of Phase 3',linewidth=4, color='red')\n",
    "\n",
    "    plt.title('Production Active Power - 24/02/2020')\n",
    "    plt.xlim('02/24/2020 06:30', '02/24/2020 19:00')\n",
    "    plt.ylim(-5,45000 )\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('[W]')\n",
    "    plt.legend()\n",
    "\n",
    "    import matplotlib.dates as md\n",
    "    ax=plt.gca()\n",
    "    xfmt = md.DateFormatter('%H:%M')\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "\n",
    "\n",
    "    axes = plt.gca()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"int0\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function responsible for defining all datasets used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasets(dfinal):\n",
    "    \n",
    "    a1 = dfinal[1440:102179].copy()\n",
    "    v1 = dfinal[102179:122339].copy()\n",
    "    a2 = dfinal[1440:122339].copy()\n",
    "    v2 = dfinal[122339:142499].copy()\n",
    "    a3 = dfinal[1440:142499].copy()\n",
    "    v3 = dfinal[142499:162659].copy()\n",
    "    a4 = dfinal[1440:162659].copy()\n",
    "    v4 = dfinal[162659:182819].copy()\n",
    "    a5 = dfinal[1440:182819].copy()\n",
    "    t5 = dfinal[182819:202979].copy()\n",
    "    d6 = dfinal[1440:202979].copy()\n",
    "    \n",
    "    return a1, a2, a3, a4, a5, v1, v2, v3, v4, t5, d6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function reponsible for implementing the Naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Predict(val):\n",
    "    \n",
    "    n_pre = 60\n",
    "    n_post = 15\n",
    "\n",
    "    vY = []\n",
    "\n",
    "    for i in range(len(val)):\n",
    "\n",
    "        ar = np.array(([row[12] for row in val[i]][-1], [row[12] for row in val[i]][-1], [row[12] for row in val[i]][-1]))\n",
    "        B = ar.reshape(-1, len(ar))\n",
    "        vY.append(B)\n",
    "\n",
    "    return np.array(vY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
