{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime,  timedelta\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    " \n",
    "from matplotlib import pyplot\n",
    "\n",
    "from solarpy import irradiance_on_plane\n",
    "from solarpy import solar_panel\n",
    "from numpy import array\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Embedding, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D, RepeatVector, Lambda, TimeDistributed, Embedding, TimeDistributed, BatchNormalization, Reshape, concatenate, Permute\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.backend import square, mean\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "#%run Database.ipynb\n",
    "%run AuxFunctions.ipynb\n",
    "\n",
    "plt.rcParams.update({'figure.figsize':(20,7), 'figure.dpi':300})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cololect building data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pv, df_consumption = collectFromDatabase(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal = getData(local = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build diferent dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, a2, a3, a4, a5, v1, v2, v3, v4, t5, d6 = getDatasets(dfinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 - Define the train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = a4.copy()\n",
    "dataset = '2'\n",
    "\n",
    "final_features = features2()\n",
    "dt = dt[final_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_val = v4.copy()\n",
    "\n",
    "final_features = features2()\n",
    "dt_val = dt_val[final_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test = t5.copy()\n",
    "\n",
    "final_features = features2()\n",
    "dt_test = dt_test[final_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dt.values\n",
    "val = dt_val.values\n",
    "test = dt_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 - Build supervised learning sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pre = 60\n",
    "n_post = 15\n",
    "\n",
    "dX, dY = [], []\n",
    "for i in range(len(train)-n_pre-n_post):\n",
    "    dX.append(train[i:i+n_pre])\n",
    "trainX = np.array(dX)\n",
    "\n",
    "for i in range(len(train)-n_pre-n_post):\n",
    "\n",
    "    ar = np.array([row[7] for row in train[i+n_pre:i+n_pre+n_post]])\n",
    "    B = ar.reshape(len(ar),-1)\n",
    "    dY.append(B)\n",
    "    \n",
    "trainY = np.array(dY)\n",
    "\n",
    "vX, vY = [], []\n",
    "for i in range(len(val)-n_pre-n_post):\n",
    "    vX.append(val[i:i+n_pre])\n",
    "valX = np.array(vX)\n",
    "\n",
    "for i in range(len(val)-n_pre-n_post):\n",
    "\n",
    "    ar = np.array([row[7] for row in val[i+n_pre:i+n_pre+n_post]])\n",
    "    B = ar.reshape(len(ar),-1)\n",
    "    vY.append(B)\n",
    "\n",
    "valY = np.array(vY)\n",
    "\n",
    "tX, tY = [], []\n",
    "for i in range(len(test)-n_pre-n_post):\n",
    "    tX.append(test[i:i+n_pre])\n",
    "testX = np.array(tX)\n",
    "\n",
    "for i in range(len(test)-n_pre-n_post):\n",
    "\n",
    "    ar = np.array([row[7] for row in test[i+n_pre:i+n_pre+n_post]])\n",
    "    B = ar.reshape(len(ar),-1)\n",
    "    tY.append(B)\n",
    "\n",
    "testY = np.array(tY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_original = trainX.copy()\n",
    "trainY_original = trainY.copy()\n",
    "valX_original = valX.copy()\n",
    "valY_original = valY.copy()\n",
    "testX_original = testX.copy()\n",
    "testY_original = testY.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape, valX.shape, valY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 - Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalersX = {}\n",
    "\n",
    "for i in range(trainX.shape[2]):\n",
    "    scalersX[i] = MinMaxScaler(feature_range=(0, 1))\n",
    "    trainX[:, :, i] = scalersX[i].fit_transform(trainX[:, :, i]) \n",
    "\n",
    "for i in range(valX.shape[2]):\n",
    "    valX[:, :, i] = scalersX[i].transform(valX[:, :, i]) \n",
    "    \n",
    "for i in range(testX.shape[2]):\n",
    "    testX[:, :, i] = scalersX[i].transform(testX[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalersY = {}\n",
    "\n",
    "for i in range(trainY.shape[2]):\n",
    "    scalersY[i] = MinMaxScaler(feature_range=(0, 1))\n",
    "    trainY[:, :, i] = scalersY[i].fit_transform(trainY[:, :, i]) \n",
    "\n",
    "for i in range(valY.shape[2]):\n",
    "    valY[:, :, i] = scalersY[i].transform(valY[:, :, i]) \n",
    "    \n",
    "for i in range(testY.shape[2]):\n",
    "    testY[:, :, i] = scalersY[i].transform(testY[:, :, i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 - Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('AZURE/files3/outputs/models/'+'ED-GRU-16-64-3-60', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights('AZURE/files3/outputs/models/'+'ED-GRU-16-64-3-60' + '.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='mse', optimizer='adam', metrics = ['mae', 'mse', tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('creating model...')\n",
    "\n",
    "model = create_model(steps_before = n_pre, steps_after = n_post, cnn = False, feature_count = 8, \\\n",
    "                     units = 256, layer = 'GRU', ft = 256, intervals = True)\n",
    "\n",
    "callbacks, path_checkpoint = callbacksFunction(model_name, dataset)\n",
    "history = train_model(model, trainX, trainY, valX, valY, 512, 100, callbacks, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('creating model...')\n",
    "model_name_intervals = model_name + 'intevals_1'\n",
    "model_intervals = create_model(steps_before = n_pre, steps_after = n_post, cnn = False, feature_count = 8, \\\n",
    "                      units = 64, layer = 'GRU', ft = 256, intervals = True)\n",
    "\n",
    "callbacks_intervals, path_checkpoint_intervals = callbacksFunction(model_name_intervals, dataset)\n",
    "history_intervals = train_model(model_intervals, trainX, trainY, valX, valY, 512, 15, callbacks_intervals, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint_intervals)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = len(history.history['loss'])\n",
    "times = callbacks[4].times \n",
    "Time_Epoch = Average(times) \n",
    "Total_Time = sum(times) \n",
    "\n",
    "Train_mae = min(history.history['mae'])\n",
    "Train_mse = min(history.history['mse'])\n",
    "Train_rmse = min(history.history['root_mean_squared_error'])\n",
    "\n",
    "Validation_mae = min(history.history['val_mae'])\n",
    "Validation_mse = min(history.history['val_mse'])\n",
    "Validation_rmse = min(history.history['val_root_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 - Perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = loaded_model.predict(testX)\n",
    "\n",
    "predict_original = predict.copy()\n",
    "\n",
    "nan_array = np.empty((n_pre - 1))\n",
    "nan_array.fill(np.nan)\n",
    "nan_array2 = np.empty(n_post)\n",
    "nan_array2.fill(np.nan)\n",
    "ind = np.arange(n_pre + n_post)\n",
    "\n",
    "for i in range(valY.shape[2]):\n",
    "    predict[:, :, i] = scalersY[i].inverse_transform(predict[:, :, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.1 - Perform multiple predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalPredictions = []\n",
    "GlobalPredictions_normalized = []\n",
    "\n",
    "nan_array = np.empty((n_pre - 1))\n",
    "nan_array.fill(np.nan)\n",
    "nan_array2 = np.empty(n_post)\n",
    "nan_array2.fill(np.nan)\n",
    "ind = np.arange(n_pre + n_post)\n",
    "\n",
    "for j in range (0,20):\n",
    "    \n",
    "    print(j, end= ' ')\n",
    "    predict_ = model.predict(testX)\n",
    "    predict_original_ = predict_.copy()\n",
    "\n",
    "    for i in range(valY.shape[2]):\n",
    "        predict_[:, :, i] = scalersY[i].inverse_transform(predict_[:, :, i])\n",
    "    \n",
    "    GlobalPredictions.append(predict_)\n",
    "    GlobalPredictions_normalized.append(predict_original_)\n",
    "    \n",
    "GlobalPredictions = np.array(GlobalPredictions)\n",
    "GlobalPredictions_normalized = np.array(GlobalPredictions_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 - Plot the predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3.5))\n",
    "for i in range(200, valX.shape[0], valX.shape[0]):\n",
    "\n",
    "   \n",
    "    forecasts_original = np.concatenate((nan_array, valX_original[i, -1:, 7], predict[i, :, 0]))\n",
    "    ground_truth = np.concatenate((nan_array, valX_original[i, -1:, 7], valY_original[i, :, 0]))\n",
    "    network_input = np.concatenate((valX_original[i, :, 7], nan_array2))\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    SMALLER_SIZE = 18\n",
    "    SMALL_SIZE = 19\n",
    "    MEDIUM_SIZE = 23\n",
    "    BIGGER_SIZE = 25\n",
    "\n",
    "    #plt.('test title', fontsize=BIGGER_SIZE)\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=SMALL_SIZE)     # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALLER_SIZE)  # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ax.plot(ind, ground_truth, 'r-o', markersize=10, markeredgecolor='black', linewidth=2, label='Av. Power')\n",
    "    ax.plot(ind, forecasts_original, 'go--', markersize=10, linewidth=2, marker='h', markerfacecolor='lightgreen', \\\n",
    "             markeredgewidth=2, label='Forecast')\n",
    "    \n",
    "    ax.plot(ind[40:], network_input[40:], '-o', markersize=10, markeredgecolor='black', linewidth=2, label='Av. Power')\n",
    "        \n",
    "    plt.ticklabel_format(axis='y', style='sci', scilimits=(5,5))\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Available Power [W]')\n",
    "    plt.title('Model 5 - Available Power - Forecast')\n",
    "    plt.legend(loc='lower left')\n",
    "    #plt.savefig('Images/' + model_name  , bbox_inches = 'tight')\n",
    "    plt.savefig('Images/' + model_name + '_op2', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(GlobalPredictions, axis=0)\n",
    "\n",
    "ci_1 = 0.80\n",
    "lower_lim_1 = np.quantile(GlobalPredictions, 0.5-ci_1/2, axis=0)\n",
    "upper_lim_1 = np.quantile(GlobalPredictions, 0.5+ci_1/2, axis=0)\n",
    "\n",
    "ci_2 = 0.95\n",
    "lower_lim_2 = np.quantile(GlobalPredictions, 0.5-ci_2/2, axis=0)\n",
    "upper_lim_2 = np.quantile(GlobalPredictions, 0.5+ci_2/2, axis=0)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3.5))\n",
    "for i in range(635, testX.shape[0], testX.shape[0]):\n",
    "\n",
    "\n",
    "    forecasts = np.concatenate((nan_array, testX_original[i, -1:, 7], mean[i, :, 0]))\n",
    "    \n",
    "    #forecasts_original = np.concatenate((nan_array, valX_original[i, -1:, 12], predict[i, :, 0]))\n",
    "    \n",
    "    lower_lim_1 = np.concatenate((nan_array, testX_original[i, -1:, 7], lower_lim_1[i, :, 0]))\n",
    "    upper_lim_1 = np.concatenate((nan_array, testX_original[i, -1:, 7], upper_lim_1[i, :, 0]))\n",
    "    lower_lim_2 = np.concatenate((nan_array, testX_original[i, -1:, 7], lower_lim_2[i, :, 0]))\n",
    "    upper_lim_2 = np.concatenate((nan_array, testX_original[i, -1:, 7], upper_lim_2[i, :, 0]))\n",
    "    \n",
    "    ground_truth = np.concatenate((nan_array, testX_original[i, -1:, 7], testY_original[i, :, 0]))\n",
    "    network_input = np.concatenate((testX_original[i, :, 7], nan_array2))\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    SMALLER_SIZE = 18\n",
    "    SMALL_SIZE = 19\n",
    "    MEDIUM_SIZE = 23\n",
    "    BIGGER_SIZE = 25\n",
    "\n",
    "    #plt.('test title', fontsize=BIGGER_SIZE)\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=SMALL_SIZE)     # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALLER_SIZE)  # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "        \n",
    "    plt.fill_between(ind, lower_lim_2, upper_lim_2, color='orange', label = str(int(ci_2 *100)) + '% CI')\n",
    "    plt.fill_between(ind, lower_lim_1, upper_lim_1, color='silver', label = str(int(ci_1 *100)) + '% CI') \n",
    "    \n",
    "    ax.plot(ind, ground_truth, 'r-o', markersize=10, markeredgecolor='black', linewidth=2, label='Av. Power')\n",
    "\n",
    "    ax.plot(ind, forecasts, 'go--', markersize=10, linewidth=2, marker='h', markerfacecolor='lightgreen', \\\n",
    "             markeredgewidth=2, label='Forecast')\n",
    "    ax.plot(ind[40:], network_input[40:], '-o', markersize=10, markeredgecolor='black', linewidth=2, label='Av. Power')\n",
    "        \n",
    "    plt.ticklabel_format(axis='y', style='sci', scilimits=(5,5))\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Available Power [W]')\n",
    "    plt.title('Model 3 - Available Power - Forecast')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.savefig('Images/' + model_name  , bbox_inches = 'tight')\n",
    "    #plt.savefig('Images/' + model_name + '_op2', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7 - Get arrays with the predictions of only 5, 10 and 5 minutes ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_normalized = []\n",
    "original_normalized = []\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "\n",
    "\n",
    "for j in range (0, valX.shape[0]):\n",
    "    for i in range(j, valX.shape[0], valX.shape[0]):\n",
    "        \n",
    "        forecasts_normalized = np.concatenate((nan_array, valX[i, -1:, 7], predict_original[i, :, 0]))\n",
    "        forecasts = np.concatenate((nan_array, valX_original[i, -1:, 7], predict[i, :, 0]))\n",
    "        \n",
    "        ground_truth_normalized = np.concatenate((nan_array, valX[i, -1:, 7], valY[i, :, 0]))\n",
    "        ground_truth = np.concatenate((nan_array, valX_original[i, -1:, 7], valY_original[i, :, 0]))\n",
    "        \n",
    "        predicted_normalized.append((forecasts_normalized[n_pre+4], forecasts_normalized[n_pre+9], forecasts_normalized[n_pre+14]))\n",
    "        predicted.append((forecasts[n_pre+4], forecasts[n_pre+9], forecasts[n_pre+14]))\n",
    "        \n",
    "        original_normalized.append((ground_truth_normalized[n_pre+4], ground_truth_normalized[n_pre+9], ground_truth_normalized[n_pre+14]))\n",
    "        original.append((ground_truth[n_pre+4], ground_truth[n_pre+9], ground_truth[n_pre+14]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mean_normalized = []\n",
    "original_normalized = []\n",
    "\n",
    "predicted_mean = []\n",
    "original = []\n",
    "\n",
    "\n",
    "for j in range (0, testX.shape[0]):\n",
    "    for i in range(j, testX.shape[0], testX.shape[0]):\n",
    "                \n",
    "        forecasts_mean_normalized = np.concatenate((nan_array, testX[i, -1:, 7], predict_original_[i, :, 0]))\n",
    "        forecasts_mean = np.concatenate((nan_array, testX_original[i, -1:, 7], predict_[i, :, 0]))\n",
    "        \n",
    "        ground_truth_normalized = np.concatenate((nan_array, testX[i, -1:, 7], testY[i, :, 0]))\n",
    "        ground_truth = np.concatenate((nan_array, testX_original[i, -1:, 7], testY_original[i, :, 0]))\n",
    "        \n",
    "        predicted_mean_normalized.append((forecasts_mean_normalized[n_pre+4], forecasts_mean_normalized[n_pre+9], forecasts_mean_normalized[n_pre+14]))\n",
    "        predicted_mean.append((forecasts_mean[n_pre+4], forecasts_mean[n_pre+9], forecasts_mean[n_pre+14]))\n",
    "        \n",
    "        original_normalized.append((ground_truth_normalized[n_pre+4], ground_truth_normalized[n_pre+9], ground_truth_normalized[n_pre+14]))\n",
    "        original.append((ground_truth[n_pre+4], ground_truth[n_pre+9], ground_truth[n_pre+14]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8 - Compute the validation errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rmse_5_normalized, validation_rmse_10_normalized, validation_rmse_15_normalized, \\\n",
    "validation_mse_5_normalized, validation_mse_10_normalized, validation_mse_15_normalized, \\\n",
    "validation_mae_5_normalized, validation_mae_10_normalized, validation_mae_15_normalized = \\\n",
    "printValidationErrorsNormalized(original_normalized, predicted_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rmse_5, validation_rmse_10, validation_rmse_15, \\\n",
    "validation_mse_5, validation_mse_10, validation_mse_15, \\\n",
    "validation_mae_5, validation_mae_10, validation_mae_15 = \\\n",
    "printValidationErrors(original, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rmse_5_normalized, validation_rmse_10_normalized, validation_rmse_15_normalized, \\\n",
    "validation_mse_5_normalized, validation_mse_10_normalized, validation_mse_15_normalized, \\\n",
    "validation_mae_5_normalized, validation_mae_10_normalized, validation_mae_15_normalized = \\\n",
    "printValidationErrorsNormalized(original_normalized, predicted_mean_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rmse_5, validation_rmse_10, validation_rmse_15, \\\n",
    "validation_mse_5, validation_mse_10, validation_mse_15, \\\n",
    "validation_mae_5, validation_mae_10, validation_mae_15 = \\\n",
    "printValidationErrors(original, predicted_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.9 - Compute the test errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse_5, test_rmse_10, test_rmse_15,\\\n",
    "test_mse_5, test_mse_10, test_mse_15,\\\n",
    "test_mae_5, test_mae_10, test_mae_15 = printTestErrors(original, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse_5_n, test_rmse_10_n, test_rmse_15_n,\\\n",
    "test_mse_5_n, test_mse_10_n, test_mse_15_n,\\\n",
    "test_mae_5_n, test_mae_10_n, test_mae_15_n = printTestErrorsNormalized(original_normalized, predicted_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse_5, test_rmse_10, test_rmse_15,\\\n",
    "test_mse_5, test_mse_10, test_mse_15,\\\n",
    "test_mae_5, test_mae_10, test_mae_15 = printTestErrors(original, predicted_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse_5_n, test_rmse_10_n, test_rmse_15_n,\\\n",
    "test_mse_5_n, test_mse_10_n, test_mse_15_n,\\\n",
    "test_mae_5_n, test_mae_10_n, test_mae_15_n = printTestErrorsNormalized(original_normalized, predicted_mean_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.10 - Plot the training and the validation error evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(history.history['loss'],label='Train MSE')\n",
    "plt.plot(history.history['val_loss'],label='Validation MSE')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Images/' + model_name + '_Loss_' + dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.11 - Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open('models/' + model_name, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('models/' + model_name + '.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open('models/' + model_name, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('models/' + model_name + '.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(x=testX, y=testY)\n",
    "print(\"loss (test-set):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_intervals.evaluate(x=valX, y=valY)\n",
    "print(\"loss (test-set):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test_' + dataset + '.csv', 'a', newline='') as file:\n",
    "    fieldnames = ['Model', \n",
    "                  'Test_MSE_n', 'Test_RMSE_n', 'Test_MAE_n',                  \n",
    "                  'Test_5_RMSE_n', 'Test_10_RMSE_n', 'Test_15_RMSE_n', \n",
    "                  'Test_5_MSE_n', 'Test_10_MSE_n', 'Test_15_MSE_n', \n",
    "                  'Test_5_MAE_n', 'Test_10_MAE_n', 'Test_15_MAE_n',\n",
    "                  \n",
    "                  'Test_5_RMSE', 'Test_10_RMSE', 'Test_15_RMSE', \n",
    "                  'Test_5_MSE', 'Test_10_MSE', 'Test_15_MSE', \n",
    "                  'Test_5_MAE', 'Test_10_MAE', 'Test_15_MAE']\n",
    "    \n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "with open('Test_' + dataset + '.csv', 'a', newline='') as file:\n",
    "    fieldnames = ['Model',\n",
    "                  'Test_MSE_n', 'Test_RMSE_n', 'Test_MAE_n',                  \n",
    "                  'Test_5_RMSE_n', 'Test_10_RMSE_n', 'Test_15_RMSE_n', \n",
    "                  'Test_5_MSE_n', 'Test_10_MSE_n', 'Test_15_MSE_n', \n",
    "                  'Test_5_MAE_n', 'Test_10_MAE_n', 'Test_15_MAE_n',\n",
    "                \n",
    "                  'Test_5_RMSE', 'Test_10_RMSE', 'Test_15_RMSE', \n",
    "                  'Test_5_MSE', 'Test_10_MSE', 'Test_15_MSE', \n",
    "                  'Test_5_MAE', 'Test_10_MAE', 'Test_15_MAE']\n",
    "    \n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "       \n",
    "    writer.writerow({'Model': model_name, \n",
    "                     \n",
    "                     'Test_MSE_n': result[2], \n",
    "                     'Test_RMSE_n': result[3],\n",
    "                     'Test_MAE_n': result[1], \n",
    "                     \n",
    "                     'Test_5_RMSE_n': test_rmse_5_n,\n",
    "                     'Test_10_RMSE_n': test_rmse_10_n,\n",
    "                     'Test_15_RMSE_n': test_rmse_15_n, \n",
    "                     'Test_5_MSE_n': test_mse_5_n,\n",
    "                     'Test_10_MSE_n': test_mse_10_n,\n",
    "                     'Test_15_MSE_n': test_mse_15_n, \n",
    "                     'Test_5_MAE_n': test_mae_5_n,\n",
    "                     'Test_10_MAE_n': test_mae_10_n,\n",
    "                     'Test_15_MAE_n': test_mae_15_n,\n",
    "                                     \n",
    "                     'Test_5_RMSE': test_rmse_5,\n",
    "                     'Test_10_RMSE': test_rmse_10,\n",
    "                     'Test_15_RMSE': test_rmse_15, \n",
    "                     'Test_5_MSE': test_mse_5,\n",
    "                     'Test_10_MSE': test_mse_10,\n",
    "                     'Test_15_MSE': test_mse_15, \n",
    "                     'Test_5_MAE': test_mae_5,\n",
    "                     'Test_10_MAE': test_mae_10,\n",
    "                     'Test_15_MAE': test_mae_15                 \n",
    "                                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ValidationProcess_' + dataset + '.csv', 'a', newline='') as file:\n",
    "    fieldnames = ['Model', 'Time', 'Epochs', 'Time_Epoch',\n",
    "                  'Train_MSE', 'Train_RMSE', 'Train_MAE', \n",
    "                  'Validation_MSE', 'Validation_RMSE', 'Validation_MAE',                  \n",
    "                  'Validation_5_RMSE', 'Validation_10_RMSE', 'Validation_15_RMSE', \n",
    "                  'Validation_5_MSE', 'Validation_10_MSE', 'Validation_15_MSE', \n",
    "                  'Validation_5_MAE', 'Validation_10_MAE', 'Validation_15_MAE']\n",
    "    \n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "with open('ValidationProcess_' + dataset + '.csv', 'a', newline='') as file:\n",
    "    fieldnames = ['Model', 'Time', 'Epochs', 'Time_Epoch',\n",
    "                  'Train_MSE', 'Train_RMSE', 'Train_MAE',\n",
    "                  'Validation_MSE', 'Validation_RMSE', 'Validation_MAE',                  \n",
    "                  \n",
    "                  'Validation_5_RMSE', 'Validation_10_RMSE', 'Validation_15_RMSE', \n",
    "                  'Validation_5_MSE', 'Validation_10_MSE', 'Validation_15_MSE', \n",
    "                  'Validation_5_MAE', 'Validation_10_MAE', 'Validation_15_MAE']\n",
    "    \n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "       \n",
    "    writer.writerow({'Model': model_name, \n",
    "                     'Time': Total_Time, \n",
    "                     'Epochs': n_epochs, \n",
    "                     'Time_Epoch': Time_Epoch, \n",
    "                     \n",
    "                     'Train_MSE': Train_mse,\n",
    "                     'Train_RMSE': Train_rmse,\n",
    "                     'Train_MAE': Train_mae, \n",
    "                     'Validation_MSE': Validation_mse, \n",
    "                     'Validation_RMSE': Validation_rmse, \n",
    "                     'Validation_MAE':Validation_mae , \n",
    "\n",
    "                  \n",
    "                     'Validation_5_RMSE': validation_rmse_5_normalized, \n",
    "                     'Validation_10_RMSE': validation_rmse_10_normalized, \n",
    "                     'Validation_15_RMSE': validation_rmse_15_normalized,\n",
    "                     'Validation_5_MSE': validation_mse_5_normalized, \n",
    "                     'Validation_10_MSE': validation_mse_10_normalized, \n",
    "                     'Validation_15_MSE': validation_mse_15_normalized,\n",
    "                     'Validation_5_MAE': validation_mae_5_normalized, \n",
    "                     'Validation_10_MAE': validation_mae_10_normalized, \n",
    "                     'Validation_15_MAE': validation_mae_15_normalized,})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
